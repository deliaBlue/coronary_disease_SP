{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edc13bd2-eb7e-478e-ac03-cced1389e10c",
   "metadata": {},
   "source": [
    "# Collaborator 5 - Validation & Model Selection. \n",
    "\n",
    "This notebook aims to validate and select the most appropiate predictive model among the 16 candidates proposed to estimate the 10-year risk of coronary heart disease (CHD). All models proposed are evaluated using a 5-fold cross-validation, and five key metrics are used (Accuracy, Sensitivity, Precision, F1 and ROC-AUC) in order to analyse the overall performance and to select the best-performing model. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c252d7-0118-4187-88c4-b045b447383c",
   "metadata": {},
   "source": [
    "### 1. Importation of the different librarys that will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e845c06-7513-4098-9705-28d431b523dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, recall_score, roc_auc_score, precision_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import joblib\n",
    "import json\n",
    "\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efa58ac-10ad-4d77-9b35-59661553ff53",
   "metadata": {},
   "source": [
    "### 2. Data & Models used.\n",
    "Here the data used and the different models generated are defined with the final parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dd9fa4bd-ca39-415b-ae25-6d2efb2c4d6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3656, 16), (3656,))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/cleaned_df.csv\")  \n",
    "target = \"ten_year_chd\"\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bbc322-d04d-4c56-bd48-a07d1b1b031e",
   "metadata": {},
   "source": [
    "##### Logistic Regression Models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c8c0a2c-fe3f-49b6-9cb8-9d95735316c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_logistic = {\n",
    "    \"LR_C01\": LogisticRegression(C=0.1, class_weight='balanced', max_iter=1000), # less regularization\n",
    "    \"LR_C10\": LogisticRegression(C=10, class_weight='balanced', max_iter=1000), # more regularization\n",
    "    \"LR_Hard_Penalization\": LogisticRegression(class_weight={0: 1, 1: 10}, max_iter=1000), # hard penalization on positive class\n",
    "    \"LR_Liblinear\": LogisticRegression(solver='liblinear', class_weight='balanced') # different solver\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea2b33f-162d-42c9-bdfc-59780857ce1c",
   "metadata": {},
   "source": [
    "##### Random Forest Models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db5ae9ba-dace-40af-b217-2451e0e5adaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_rf = {\n",
    "    \"RF_Balanced\": RandomForestClassifier(class_weight='balanced', random_state=42), # balanced classes\n",
    "    \"RF_Balanced_Subsample\": RandomForestClassifier(class_weight='balanced_subsample', random_state=42), # balanced per bootstrap sample\n",
    "    \"RF_Limited_Depth\": RandomForestClassifier(max_depth=5, class_weight='balanced', random_state=42), # limit depth to reduce overfitting\n",
    "    \"RF_More_Trees\": RandomForestClassifier(n_estimators=500, class_weight='balanced', random_state=42) # more trees\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010ab07a-2d9e-4be2-bd78-b0aa0d4f426b",
   "metadata": {},
   "source": [
    "##### SVM Models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba02d2f6-3bea-440e-af8e-2b05bf55049c",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_svm = {\n",
    "    \"SVM_RBF_Standard\": SVC(kernel='rbf', class_weight='balanced', probability=True), # standard RBF kernel\n",
    "    \"SVM_Linear\": SVC(kernel='linear', class_weight='balanced', probability=True), # linear kernel\n",
    "    \"SVM_Polynomial\": SVC(kernel='poly', degree=3, class_weight='balanced', probability=True), # polynomial kernel\n",
    "    \"SVM_C_High\": SVC(C=10, class_weight='balanced', probability=True) # high C value for less regularization\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed712d69-d6c7-4ead-9966-cf31eea140f9",
   "metadata": {},
   "source": [
    "##### KNN Models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea964927-884a-482b-91e2-c1e047638c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_knn = {\n",
    "    \"KNN_3\": KNeighborsClassifier(n_neighbors=3), # number of neighbors = 3\n",
    "    \"KNN_7\": KNeighborsClassifier(n_neighbors=7), # number of neighbors = 7\n",
    "    \"KNN_Weight_Distance\": KNeighborsClassifier(n_neighbors=5, weights='distance'), # weight by distance\n",
    "    \"KNN_Algorithm_BallTree\": KNeighborsClassifier(algorithm='ball_tree') ## algorithm choice\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3e7ce7-e4ad-4f0c-81d4-1294f2cdcd31",
   "metadata": {},
   "source": [
    "### 3. Validation Startegy.\n",
    "\n",
    "This section evaluates all candidate models using the same validation framework to ensure a comparable assessment of their performance. A 5‑fold stratified cross‑validation procedure is applied on the full dataset, using the binary target variable `ten_year_chd` (1 = CHD within 10 years, 0 = no CHD). In each fold, the data are split into training and validation subsets while preserving the original class distribution, the model is trained on the training portion and evaluated on the corresponding validation portion. The predictions from all folds are then aggregated to compute global performance metrics for each model.\n",
    "\n",
    "For each configuration the following metric will be obtained: \n",
    "- **Accuracy**: proportion of correct predictions among all the predictions made.\n",
    "- **Recall (Sensitivity)**:  proportion of actual positive cases that are correctly identified as positive (also call true positive rate).\n",
    "- **Precision (Positive Class)**: proportion of predicted positives cases that are actually positive.\n",
    "- **F1-score**: harmonnic mean between precision and recall for the positive class. \n",
    "- **ROC-AUC**: summarising the model's ability to distinguish between positive and negative classes across all classification thresholds.\n",
    "\n",
    "This common validation strategy allows a consistent comparison of all models and supports the selection of the most appropriate one. Having in mind the preventive nature of a predictive model like this one, the main objective is to correctly identify patients at high risk of developing CHD (prioritising high recall), while maintaining a reasonable level of false positives (acceptable precision and F1-score). So, the final selection is based on a balance between Recall, F1-score, and ROC-AUC, rather than only on accuracy. \n",
    "\n",
    "To optimise the analysis, the evaluation will be made first accross each model family (Logistic Regression, Random Forest, SVM and KNN) and then across the best performing models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "609215ee-635c-4fbc-8bf3-95b32c9c8e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_cv(model, X, y, cv=5): #the fuction will receive the model to evaluate, the data ( X and y) and the number of folds\n",
    "    kf = KFold(n_splits=cv, shuffle=True, random_state=seed) #divide the data into the different sections\n",
    "    y_prob = cross_val_predict(model, X, y, cv = kf, method='predict_proba')[:,1] #train the model cv-times each time test in the remaining part\n",
    "    y_pred = (y_prob >= 0.5).astype(int) #determine 0 or 1 based on the probability obtained\n",
    "\n",
    "    acc = accuracy_score(y, y_pred)\n",
    "    rec = recall_score(y, y_pred)\n",
    "    prec = precision_score(y,y_pred, zero_division=0)\n",
    "    f1 = f1_score(y,y_pred)\n",
    "    auc = roc_auc_score(y, y_prob)\n",
    "    \n",
    "    return acc, rec, prec, f1, auc #returns all the metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba660dc6-3086-4f47-abec-e18357fac137",
   "metadata": {},
   "source": [
    "#### Logistic Regression Models Comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84156de8-3554-46a7-9128-9292b58864c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR_C01</td>\n",
       "      <td>0.674234</td>\n",
       "      <td>0.664273</td>\n",
       "      <td>0.269287</td>\n",
       "      <td>0.383221</td>\n",
       "      <td>0.727306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LR_C10</td>\n",
       "      <td>0.672593</td>\n",
       "      <td>0.662478</td>\n",
       "      <td>0.267779</td>\n",
       "      <td>0.381395</td>\n",
       "      <td>0.725980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LR_Hard_Penalization</td>\n",
       "      <td>0.506291</td>\n",
       "      <td>0.850987</td>\n",
       "      <td>0.215847</td>\n",
       "      <td>0.344352</td>\n",
       "      <td>0.725509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LR_Liblinear</td>\n",
       "      <td>0.672593</td>\n",
       "      <td>0.662478</td>\n",
       "      <td>0.267779</td>\n",
       "      <td>0.381395</td>\n",
       "      <td>0.726252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  accuracy    recall  precision  F1-score   roc_auc\n",
       "0                LR_C01  0.674234  0.664273   0.269287  0.383221  0.727306\n",
       "1                LR_C10  0.672593  0.662478   0.267779  0.381395  0.725980\n",
       "2  LR_Hard_Penalization  0.506291  0.850987   0.215847  0.344352  0.725509\n",
       "3          LR_Liblinear  0.672593  0.662478   0.267779  0.381395  0.726252"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_logistic = []\n",
    "\n",
    "for name, model in models_logistic.items():\n",
    "    acc, rec, prec, f1, auc = evaluate_model_cv(model, X, y, cv=5)\n",
    "    results_logistic.append({\n",
    "        \"model\": name,\n",
    "        \"accuracy\": acc,\n",
    "        \"recall\": rec,\n",
    "        \"precision\": prec,\n",
    "        \"F1-score\": f1,\n",
    "        \"roc_auc\": auc,})\n",
    "\n",
    "results_logistic = pd.DataFrame(results_logistic)\n",
    "results_logistic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3407dcf-5220-4eba-b189-6280f96e703d",
   "metadata": {},
   "source": [
    "All the four configurations of the Logistic Regression family show a reasonable ability to identify future CHD cases. The three balanced models (LR_C01, LR_C10 and LR_Liblinear) obtained very similar metrics, with accuracy around 0.67, recall ≈ 0.66, precision ≈ 0.27, F1-scores ≈ 0.38 and ROC-AUC ≈ 0.73. This values indicate that this models correctly identify a substantial proprotion of future cases, while keeping an acceptable rate of false positives, with a good general discriminative ability. \n",
    "\n",
    "In contrast, the LR_Hard_Penalization model, that increases the weigth of the positive class, has a higher recall (≈ 0.85) but sacrifice the accuracy (≈0.51) and precision (≈0.22), so a lower F1-scores is obtained. Finally, the ROC-AUC is comparable across the four models. This model, is at the end, more aggressive, and maximise sensitivity, but at the cost of creating more false alarm. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183f3bb5-1efe-447f-84b4-75757aeead14",
   "metadata": {},
   "source": [
    "#### Random Forest Comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a95c3e6f-1afe-4f96-afe4-073911bd4911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF_Balanced</td>\n",
       "      <td>0.847374</td>\n",
       "      <td>0.041293</td>\n",
       "      <td>0.489362</td>\n",
       "      <td>0.076159</td>\n",
       "      <td>0.686498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF_Balanced_Subsample</td>\n",
       "      <td>0.847374</td>\n",
       "      <td>0.037702</td>\n",
       "      <td>0.488372</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.684066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RF_Limited_Depth</td>\n",
       "      <td>0.717724</td>\n",
       "      <td>0.563734</td>\n",
       "      <td>0.284678</td>\n",
       "      <td>0.378313</td>\n",
       "      <td>0.712403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF_More_Trees</td>\n",
       "      <td>0.847101</td>\n",
       "      <td>0.030521</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.057336</td>\n",
       "      <td>0.692011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   model  accuracy    recall  precision  F1-score   roc_auc\n",
       "0            RF_Balanced  0.847374  0.041293   0.489362  0.076159  0.686498\n",
       "1  RF_Balanced_Subsample  0.847374  0.037702   0.488372  0.070000  0.684066\n",
       "2       RF_Limited_Depth  0.717724  0.563734   0.284678  0.378313  0.712403\n",
       "3          RF_More_Trees  0.847101  0.030521   0.472222  0.057336  0.692011"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_rf = []\n",
    "\n",
    "for name, model in models_rf.items():\n",
    "    acc, rec, prec, f1, auc = evaluate_model_cv(model, X, y, cv=5)\n",
    "    results_rf.append({\n",
    "        \"model\": name,\n",
    "        \"accuracy\": acc,\n",
    "        \"recall\": rec,\n",
    "        \"precision\": prec,\n",
    "        \"F1-score\": f1,\n",
    "        \"roc_auc\": auc,})\n",
    "\n",
    "results_rf = pd.DataFrame(results_rf)\n",
    "results_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dece6e7-8c3f-4725-b8cc-dc22d8fca122",
   "metadata": {},
   "source": [
    "In the Random Forest family, three of the configurations (RF_Balanced, RF_Balanced_Subsample and RF_More_Trees) obtained high overall accuracy (≈ 0.85) and a reasonable precision, but with an extremly low recall value, therefore the F1-scores is also low. This models fails to detect the vast majority of positive cases.  \n",
    "\n",
    "In contrast, the RF_Limited_Depth model has a more balanced behaviour, while having a lower accuracy (≈ 0.72) but with a higher recall (≈ 0.56) and moderate precision, with a final F1-scores of around 0.38 and a ROC-AUC of 0.71. Therefore, this model is the best of the Random Forest configuration, since it offers a more balance performance "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24125233-6c4b-428e-8031-c954714343fa",
   "metadata": {},
   "source": [
    "#### SVM Comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f1d7a56-f80b-491b-acf3-b92c26b8d145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM_RBF_Standard</td>\n",
       "      <td>0.847648</td>\n",
       "      <td>0.003591</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.007130</td>\n",
       "      <td>0.699889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM_Linear</td>\n",
       "      <td>0.851751</td>\n",
       "      <td>0.041293</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.078231</td>\n",
       "      <td>0.724017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM_Polynomial</td>\n",
       "      <td>0.847648</td>\n",
       "      <td>0.025135</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.047863</td>\n",
       "      <td>0.677542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM_C_High</td>\n",
       "      <td>0.847921</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003584</td>\n",
       "      <td>0.615751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model  accuracy    recall  precision  F1-score   roc_auc\n",
       "0  SVM_RBF_Standard  0.847648  0.003591   0.500000  0.007130  0.699889\n",
       "1        SVM_Linear  0.851751  0.041293   0.741935  0.078231  0.724017\n",
       "2    SVM_Polynomial  0.847648  0.025135   0.500000  0.047863  0.677542\n",
       "3        SVM_C_High  0.847921  0.001795   1.000000  0.003584  0.615751"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_svm = []\n",
    "\n",
    "for name, model in models_svm.items():\n",
    "    acc, rec, prec, f1, auc = evaluate_model_cv(model, X, y, cv=5)\n",
    "    results_svm.append({\n",
    "        \"model\": name,\n",
    "        \"accuracy\": acc,\n",
    "        \"recall\": rec,\n",
    "        \"precision\": prec,\n",
    "        \"F1-score\": f1,\n",
    "        \"roc_auc\": auc,})\n",
    "\n",
    "results_svm = pd.DataFrame(results_svm)\n",
    "results_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea0ab74-2c2d-4f18-b258-76b7562b2d78",
   "metadata": {},
   "source": [
    "All the SVM models perform poorly in terms of correctly identifying future CHD cases. While all of them achieved high overall accuracy (≈ 0.85) and moderate ROC-AUC, tehir recall and F1-scores for the positive class are extremely low. The sensitivity remains close to zero, meaning that the vast majority of the patients that develop CHD in the future were classified as non-CHD. This may be due to the threshold of 0.5 stablished on the predicted probabilities or to the strong class imbalance in the dataset. As a conclusion, non of the SVM models i suitable for the prediction task. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e25fb02-c727-47c4-a0ad-ad9139790a6f",
   "metadata": {},
   "source": [
    "#### KNN Comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "908bdcf0-7562-4748-97de-e87e53c5ec35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN_3</td>\n",
       "      <td>0.821389</td>\n",
       "      <td>0.129264</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.180678</td>\n",
       "      <td>0.604869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN_7</td>\n",
       "      <td>0.840263</td>\n",
       "      <td>0.077199</td>\n",
       "      <td>0.380531</td>\n",
       "      <td>0.128358</td>\n",
       "      <td>0.654779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN_Weight_Distance</td>\n",
       "      <td>0.829869</td>\n",
       "      <td>0.066427</td>\n",
       "      <td>0.266187</td>\n",
       "      <td>0.106322</td>\n",
       "      <td>0.635480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNN_Algorithm_BallTree</td>\n",
       "      <td>0.829869</td>\n",
       "      <td>0.064632</td>\n",
       "      <td>0.262774</td>\n",
       "      <td>0.103746</td>\n",
       "      <td>0.632968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  accuracy    recall  precision  F1-score   roc_auc\n",
       "0                   KNN_3  0.821389  0.129264   0.300000  0.180678  0.604869\n",
       "1                   KNN_7  0.840263  0.077199   0.380531  0.128358  0.654779\n",
       "2     KNN_Weight_Distance  0.829869  0.066427   0.266187  0.106322  0.635480\n",
       "3  KNN_Algorithm_BallTree  0.829869  0.064632   0.262774  0.103746  0.632968"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_knn = []\n",
    "\n",
    "for name, model in models_knn.items():\n",
    "    acc, rec, prec, f1, auc = evaluate_model_cv(model, X, y, cv=5)\n",
    "    results_knn.append({\n",
    "        \"model\": name,\n",
    "        \"accuracy\": acc,\n",
    "        \"recall\": rec,\n",
    "        \"precision\": prec,\n",
    "        \"F1-score\": f1,\n",
    "        \"roc_auc\": auc,})\n",
    "\n",
    "results_knn = pd.DataFrame(results_knn)\n",
    "results_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236d13f2-4665-4a46-b08a-33a73fd1275f",
   "metadata": {},
   "source": [
    "In general, the K-Nearest Neighbours (KNN) models obtained a good overall accuracy (≈0.82-0.84) and ROC-AUC values, bute their recall and F1-scores for the positive class are extremely low. For the four configurations the recall is ranged between 0.06 to 0.13, and F1-scores are below 0.2. This indicates that these models do not classify correctly the patients that will develop CHD. Again, this behaviour is consitent with the strong class imbalance in the dataset, as KNN tends to favour the majority class. As a consequence, non of these models is sufficiently sensitive for the intended predictive model, and will not be consider as candidates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5f6ea6-78aa-4a33-81bc-02802ca73e09",
   "metadata": {},
   "source": [
    "### 4. Final Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf28880-32dc-4541-9148-06b0b2d4351b",
   "metadata": {},
   "source": [
    "Based on the prevoius analysis made by blocks, SVM and KNN models were discarded due to the extremely low recall and F1-scores values. From the Random Forest family, only the RF_Limited_Depth_ configuration provides acceptable metrics, and will be consider for the final selection. All four variants from the Logistic Regression (LR_C01, LR_C10, LR_Liblinear and LR_Hard_Penalization) showed strong performance, with suitable values of recall and F1-scores. Therefore, the final selection will only compare the four logistic regresion models and RF_Limited_Depth. \n",
    "\n",
    "As mentioned before, given the predictive and preventive nature of the model, the selection is based primarily on the performance of the positive class. The main objective is to correctly identify patients at high risk of developing CHD (high Recall), while maintaining an acceptable balance between false positives and false negatives (F1‑score) and a good overall discriminative ability (ROC‑AUC). Accuracy is considered but not used as the primary criterion due to the class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "037f6fa8-aa79-441b-b757-67a5a68b762b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR_C01</td>\n",
       "      <td>0.674234</td>\n",
       "      <td>0.664273</td>\n",
       "      <td>0.269287</td>\n",
       "      <td>0.383221</td>\n",
       "      <td>0.727306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LR_C10</td>\n",
       "      <td>0.672593</td>\n",
       "      <td>0.662478</td>\n",
       "      <td>0.267779</td>\n",
       "      <td>0.381395</td>\n",
       "      <td>0.725980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LR_Hard_Penalization</td>\n",
       "      <td>0.506291</td>\n",
       "      <td>0.850987</td>\n",
       "      <td>0.215847</td>\n",
       "      <td>0.344352</td>\n",
       "      <td>0.725509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LR_Liblinear</td>\n",
       "      <td>0.672593</td>\n",
       "      <td>0.662478</td>\n",
       "      <td>0.267779</td>\n",
       "      <td>0.381395</td>\n",
       "      <td>0.726252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RF_Limited_Depth</td>\n",
       "      <td>0.717724</td>\n",
       "      <td>0.563734</td>\n",
       "      <td>0.284678</td>\n",
       "      <td>0.378313</td>\n",
       "      <td>0.712403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  accuracy    recall  precision  F1-score   roc_auc\n",
       "0                LR_C01  0.674234  0.664273   0.269287  0.383221  0.727306\n",
       "1                LR_C10  0.672593  0.662478   0.267779  0.381395  0.725980\n",
       "2  LR_Hard_Penalization  0.506291  0.850987   0.215847  0.344352  0.725509\n",
       "3          LR_Liblinear  0.672593  0.662478   0.267779  0.381395  0.726252\n",
       "4      RF_Limited_Depth  0.717724  0.563734   0.284678  0.378313  0.712403"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.concat(\n",
    "    [results_logistic, results_rf, results_svm, results_knn],\n",
    "    ignore_index=True)\n",
    "options = [\"LR_C01\",\"LR_C10\",\"LR_Liblinear\", \"LR_Hard_Penalization\", \"RF_Limited_Depth\",]\n",
    "final_options = results[results[\"model\"].isin(options)].reset_index(drop=True)\n",
    "final_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76837ddf-25f1-4fa3-bc6a-22b284ec48d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 700x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics = [\"recall\", \"precision\", \"F1-score\", \"roc_auc\"]\n",
    "plot_df = (results[results[\"model\"].isin(options)].set_index(\"model\")[metrics].T  )\n",
    "\n",
    "colors =  [ \"#4C72B0\", \"#55A868\", \"#C44E52\", \"#8172B3\", \"#937860\",]\n",
    "plt.figure(figsize=(7, 4))\n",
    "plot_df.plot(kind=\"bar\",color=colors,edgecolor=\"black\", linewidth=0.5)\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(0, 1)\n",
    "plt.title(\"Metrics for the final selection\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(title=\"Model\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac99f8d6-64cc-4a9b-a3d7-4df7be99e300",
   "metadata": {},
   "source": [
    "##### Final Selection\n",
    "Among the finalist options, the LR_Hard_Penalization configuration is the one that achieves a higher sensitivity, with a recall of 0.85 and a ROC-AUC of 0.73. Although its overall accuracy is lower than the in the most conservatives, such as LR_C01. While this may be a more aggresive model, given the preventive setting of 10-year CHD risk prediction, where failing to indenitfy high-risk patients is consider more harmful than over-estimating risk, this configuration is the best among the ones evaluated. For this reason, LR_Hard_Penalization is selected as the final model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f96bf8e-6e89-402a-a607-9fafe8220ca8",
   "metadata": {},
   "source": [
    "### 5. Feature scheme and model export\n",
    "\n",
    "To complete the validation and model selection process, we input feature scheme expected by the final model and export the selected configuration for downstream deployment. This ensures reproducibility, compatibility, and clarity for future inference steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e789d30e-c48e-4c0f-9573-3f683b684906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature schema (input order):\n",
      "- sex\n",
      "- age\n",
      "- education_level\n",
      "- current_smoker\n",
      "- bp_meds\n",
      "- prevalent_stroke\n",
      "- prevalent_hypertension\n",
      "- diabetes\n",
      "- total_cholesterol\n",
      "- systolic_bp\n",
      "- diastolic_bp\n",
      "- bmi\n",
      "- heart_rate\n",
      "- glucose\n",
      "- smoker_intensity\n",
      "- pulse_pressure\n"
     ]
    }
   ],
   "source": [
    "# Feature Schema -\n",
    "feature_schema = X.columns.tolist()\n",
    "\n",
    "print(\"Feature schema (input order):\")\n",
    "for f in feature_schema:\n",
    "    print(\"-\",f)\n",
    "\n",
    "# Save the feature schema as JSON file\n",
    "with open(\"../model/feature_schema.json\",\"w\") as f:\n",
    "    json.dump(feature_schema, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af007350-fa29-483b-a196-666d9f91be84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../model/final_model.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final Model Export \n",
    "final_model = LogisticRegression(class_weight={0: 1, 1: 10}, max_iter=1000)\n",
    "final_model.fit(X,y)\n",
    "\n",
    "joblib.dump(final_model, \"../model/final_model.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "98122379-5528-494d-a26b-e9a656196065",
   "metadata": {},
   "source": [
    "### Summary - Validation & Model Selection\n",
    "\n",
    "In this section, a set of 16 models (logistic regression, random forest, SVM and KNN) was evaluated using 5-fold cross-validation to predict 10-year coronary heart disease risk. Model performance was assessed with accuracy, recall, precision, F1-score and ROC-AUC, giving it more importance to sensitivity. Due to the preventive context, where missing high-risk patients is more critical than generating false positives. After comparing model families and focusing on those with acceptable F1-score and ROC-AUC, four finalists were selected. Finally, the LR_Hard_Penalization configuration (logistic regression with increased weight on the positive class) was selected as the final model since is the one with a higher sensitivity while the F1-score and ROC-AUC are not sacrifice, being the better suited. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (master)",
   "language": "python",
   "name": "master"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
