{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa896b0c",
   "metadata": {},
   "source": [
    "# Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7789aa",
   "metadata": {},
   "source": [
    "**Author:**  Cesar Merino\n",
    "\n",
    "**Goal:** Train multiple predictive models for coronary heart disease.\n",
    "\n",
    "**Input:**\n",
    "* Cleaned DataFrame from [Normalization & Correlation](./2_normalization_correlation.ipynb)\n",
    "\n",
    "**Tasks:**  \n",
    "• Split data into training and testing sets.  \n",
    "• Train Logistic Regression (mandatory).  \n",
    "• Train KNN model.  \n",
    "• Train one tree-based model (Random Forest or similar).  \n",
    "• Address class imbalance if needed.  \n",
    "• Save trained models.  \n",
    "• Record performance metrics.\n",
    "  \n",
    "**Deliverables:**  \n",
    "• Trained models.  \n",
    "• Initial performance metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6010e5-ba4c-4dd6-805c-481044a71bc2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 0. Imports and Global Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "326c46a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80fe3097",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = pd.read_csv('../data/cleaned_df.csv')\n",
    "\n",
    "final_features = ['sex',\n",
    " 'age',\n",
    " 'education_level',\n",
    " 'current_smoker',\n",
    " 'bp_meds',\n",
    " 'prevalent_stroke',\n",
    " 'prevalent_hypertension',\n",
    " 'diabetes',\n",
    " 'total_cholesterol',\n",
    " 'systolic_bp',\n",
    " 'diastolic_bp',\n",
    " 'bmi',\n",
    " 'heart_rate',\n",
    " 'glucose',\n",
    " 'ten_year_chd',\n",
    " 'smoker_intensity',\n",
    " 'pulse_pressure']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(cleaned_df[final_features].drop('ten_year_chd', axis=1),\n",
    "                                                    cleaned_df['ten_year_chd'],\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=cleaned_df['ten_year_chd'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23fd284",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. General models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90d1b703",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"logistic\": LogisticRegression(),\n",
    "    \"random_forest\": RandomForestClassifier(random_state=42),\n",
    "    \"svm\": SVC(probability=True),\n",
    "    \"knn\": KNeighborsClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd76e608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- logistic ---\n",
      "Accuracy: 0.86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.99      0.92       620\n",
      "           1       0.73      0.14      0.24       112\n",
      "\n",
      "    accuracy                           0.86       732\n",
      "   macro avg       0.80      0.57      0.58       732\n",
      "weighted avg       0.84      0.86      0.82       732\n",
      "\n",
      "--- random_forest ---\n",
      "Accuracy: 0.84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.97      0.91       620\n",
      "           1       0.36      0.08      0.13       112\n",
      "\n",
      "    accuracy                           0.84       732\n",
      "   macro avg       0.61      0.53      0.52       732\n",
      "weighted avg       0.78      0.84      0.79       732\n",
      "\n",
      "--- svm ---\n",
      "Accuracy: 0.85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       620\n",
      "           1       0.40      0.02      0.03       112\n",
      "\n",
      "    accuracy                           0.85       732\n",
      "   macro avg       0.62      0.51      0.48       732\n",
      "weighted avg       0.78      0.85      0.78       732\n",
      "\n",
      "--- knn ---\n",
      "Accuracy: 0.84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.91       620\n",
      "           1       0.41      0.11      0.17       112\n",
      "\n",
      "    accuracy                           0.84       732\n",
      "   macro avg       0.64      0.54      0.54       732\n",
      "weighted avg       0.79      0.84      0.80       732\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    print(f\"--- {name} ---\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, predictions):.2f}\")\n",
    "    print(classification_report(y_test, predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2310f51b",
   "metadata": {},
   "source": [
    "As classes are unblanced the general results are pretty bad. Even if the accuracy might be higher than 0.8, the recall is low, meaning that the model is always predicting 'healthy'. In order to address this issue, the models usually have a parameter to give the same importance to each value of the classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2987a4f6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Balanced models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5a636b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- logistic ---\n",
      "Accuracy: 0.69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.70      0.79       620\n",
      "           1       0.28      0.67      0.40       112\n",
      "\n",
      "    accuracy                           0.69       732\n",
      "   macro avg       0.60      0.68      0.60       732\n",
      "weighted avg       0.82      0.69      0.73       732\n",
      "\n",
      "--- random_forest ---\n",
      "Accuracy: 0.85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92       620\n",
      "           1       0.73      0.07      0.13       112\n",
      "\n",
      "    accuracy                           0.85       732\n",
      "   macro avg       0.79      0.53      0.53       732\n",
      "weighted avg       0.84      0.85      0.80       732\n",
      "\n",
      "--- svm ---\n",
      "Accuracy: 0.71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.72      0.81       620\n",
      "           1       0.29      0.63      0.40       112\n",
      "\n",
      "    accuracy                           0.71       732\n",
      "   macro avg       0.60      0.68      0.60       732\n",
      "weighted avg       0.82      0.71      0.75       732\n",
      "\n",
      "--- knn ---\n",
      "Accuracy: 0.84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.91       620\n",
      "           1       0.41      0.11      0.17       112\n",
      "\n",
      "    accuracy                           0.84       732\n",
      "   macro avg       0.64      0.54      0.54       732\n",
      "weighted avg       0.79      0.84      0.80       732\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"logistic\": LogisticRegression(class_weight='balanced'),\n",
    "    \"random_forest\": RandomForestClassifier(random_state=42, class_weight='balanced'),\n",
    "    \"svm\": SVC(probability=True, class_weight='balanced'),\n",
    "    \"knn\": KNeighborsClassifier()\n",
    "}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    print(f\"--- {name} ---\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, predictions):.2f}\")\n",
    "    print(classification_report(y_test, predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2236e1b",
   "metadata": {},
   "source": [
    "As it can be seen, the accuracies on logistic regression and SVM has dropped down. Despite this, the results are better as the recall is now over 60%, meaning that the models are able to detect and differentiate some of the cases. Now the hyperparameters will be changed to try to obtain better results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55566dbb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Tweak models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44891c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- LR_C01 ---\n",
      "Accuracy: 0.69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.70      0.79       620\n",
      "           1       0.28      0.66      0.39       112\n",
      "\n",
      "    accuracy                           0.69       732\n",
      "   macro avg       0.60      0.68      0.59       732\n",
      "weighted avg       0.82      0.69      0.73       732\n",
      "\n",
      "--- LR_C10 ---\n",
      "Accuracy: 0.69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.70      0.79       620\n",
      "           1       0.28      0.67      0.40       112\n",
      "\n",
      "    accuracy                           0.69       732\n",
      "   macro avg       0.60      0.68      0.60       732\n",
      "weighted avg       0.82      0.69      0.73       732\n",
      "\n",
      "--- LR_Hard_Penalization ---\n",
      "Accuracy: 0.52\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.46      0.62       620\n",
      "           1       0.22      0.85      0.35       112\n",
      "\n",
      "    accuracy                           0.52       732\n",
      "   macro avg       0.58      0.65      0.48       732\n",
      "weighted avg       0.83      0.52      0.58       732\n",
      "\n",
      "--- LR_Liblinear ---\n",
      "Accuracy: 0.69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.70      0.79       620\n",
      "           1       0.28      0.67      0.40       112\n",
      "\n",
      "    accuracy                           0.69       732\n",
      "   macro avg       0.60      0.68      0.60       732\n",
      "weighted avg       0.82      0.69      0.73       732\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models_logistic = {\n",
    "    \"LR_C01\": LogisticRegression(C=0.1, class_weight='balanced', max_iter=1000), # less regularization\n",
    "    \"LR_C10\": LogisticRegression(C=10, class_weight='balanced', max_iter=1000), # more regularization\n",
    "    \"LR_Hard_Penalization\": LogisticRegression(class_weight={0: 1, 1: 10}, max_iter=1000), # hard penalization on positive class\n",
    "    \"LR_Liblinear\": LogisticRegression(solver='liblinear', class_weight='balanced') # different solver\n",
    "}\n",
    "for name, model in models_logistic.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    print(f\"--- {name} ---\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, predictions):.2f}\")\n",
    "    print(classification_report(y_test, predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e31a8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RF_Balanced ---\n",
      "Accuracy: 0.85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92       620\n",
      "           1       0.73      0.07      0.13       112\n",
      "\n",
      "    accuracy                           0.85       732\n",
      "   macro avg       0.79      0.53      0.53       732\n",
      "weighted avg       0.84      0.85      0.80       732\n",
      "\n",
      "--- RF_Balanced_Subsample ---\n",
      "Accuracy: 0.85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.99      0.92       620\n",
      "           1       0.67      0.07      0.13       112\n",
      "\n",
      "    accuracy                           0.85       732\n",
      "   macro avg       0.76      0.53      0.52       732\n",
      "weighted avg       0.83      0.85      0.80       732\n",
      "\n",
      "--- RF_Limited_Depth ---\n",
      "Accuracy: 0.73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.77      0.83       620\n",
      "           1       0.30      0.54      0.38       112\n",
      "\n",
      "    accuracy                           0.73       732\n",
      "   macro avg       0.60      0.66      0.61       732\n",
      "weighted avg       0.81      0.73      0.76       732\n",
      "\n",
      "--- RF_More_Trees ---\n",
      "Accuracy: 0.85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       620\n",
      "           1       0.67      0.05      0.10       112\n",
      "\n",
      "    accuracy                           0.85       732\n",
      "   macro avg       0.76      0.52      0.51       732\n",
      "weighted avg       0.82      0.85      0.79       732\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models_rf = {\n",
    "    \"RF_Balanced\": RandomForestClassifier(class_weight='balanced', random_state=42), # balanced classes\n",
    "    \"RF_Balanced_Subsample\": RandomForestClassifier(class_weight='balanced_subsample', random_state=42), # balanced per bootstrap sample\n",
    "    \"RF_Limited_Depth\": RandomForestClassifier(max_depth=5, class_weight='balanced', random_state=42), # limit depth to reduce overfitting\n",
    "    \"RF_More_Trees\": RandomForestClassifier(n_estimators=500, class_weight='balanced', random_state=42) # more trees\n",
    "}\n",
    "\n",
    "for name, model in models_rf.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    print(f\"--- {name} ---\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, predictions):.2f}\")\n",
    "    print(classification_report(y_test, predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2f5c10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- SVM_RBF_Standard ---\n",
      "Accuracy: 0.71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.72      0.81       620\n",
      "           1       0.29      0.63      0.40       112\n",
      "\n",
      "    accuracy                           0.71       732\n",
      "   macro avg       0.60      0.68      0.60       732\n",
      "weighted avg       0.82      0.71      0.75       732\n",
      "\n",
      "--- SVM_Linear ---\n",
      "Accuracy: 0.67\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.67      0.78       620\n",
      "           1       0.28      0.71      0.40       112\n",
      "\n",
      "    accuracy                           0.67       732\n",
      "   macro avg       0.60      0.69      0.59       732\n",
      "weighted avg       0.83      0.67      0.72       732\n",
      "\n",
      "--- SVM_Polynomial ---\n",
      "Accuracy: 0.77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.82      0.86       620\n",
      "           1       0.34      0.53      0.41       112\n",
      "\n",
      "    accuracy                           0.77       732\n",
      "   macro avg       0.62      0.67      0.64       732\n",
      "weighted avg       0.82      0.77      0.79       732\n",
      "\n",
      "--- SVM_C_High ---\n",
      "Accuracy: 0.74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.79      0.84       620\n",
      "           1       0.28      0.44      0.34       112\n",
      "\n",
      "    accuracy                           0.74       732\n",
      "   macro avg       0.58      0.61      0.59       732\n",
      "weighted avg       0.79      0.74      0.76       732\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models_svm = {\n",
    "    \"SVM_RBF_Standard\": SVC(kernel='rbf', class_weight='balanced', probability=True), # standard RBF kernel\n",
    "    \"SVM_Linear\": SVC(kernel='linear', class_weight='balanced', probability=True), # linear kernel\n",
    "    \"SVM_Polynomial\": SVC(kernel='poly', degree=3, class_weight='balanced', probability=True), # polynomial kernel\n",
    "    \"SVM_C_High\": SVC(C=10, class_weight='balanced', probability=True) # high C value for less regularization\n",
    "}\n",
    "\n",
    "for name, model in models_svm.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    print(f\"--- {name} ---\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, predictions):.2f}\")\n",
    "    print(classification_report(y_test, predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a30b3a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- KNN_3 ---\n",
      "Accuracy: 0.83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91       620\n",
      "           1       0.36      0.13      0.19       112\n",
      "\n",
      "    accuracy                           0.83       732\n",
      "   macro avg       0.61      0.55      0.55       732\n",
      "weighted avg       0.78      0.83      0.80       732\n",
      "\n",
      "--- KNN_7 ---\n",
      "Accuracy: 0.84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.98      0.91       620\n",
      "           1       0.46      0.11      0.17       112\n",
      "\n",
      "    accuracy                           0.84       732\n",
      "   macro avg       0.66      0.54      0.54       732\n",
      "weighted avg       0.80      0.84      0.80       732\n",
      "\n",
      "--- KNN_Weight_Distance ---\n",
      "Accuracy: 0.84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.91       620\n",
      "           1       0.41      0.11      0.17       112\n",
      "\n",
      "    accuracy                           0.84       732\n",
      "   macro avg       0.64      0.54      0.54       732\n",
      "weighted avg       0.79      0.84      0.80       732\n",
      "\n",
      "--- KNN_Algorithm_BallTree ---\n",
      "Accuracy: 0.84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.91       620\n",
      "           1       0.41      0.11      0.17       112\n",
      "\n",
      "    accuracy                           0.84       732\n",
      "   macro avg       0.64      0.54      0.54       732\n",
      "weighted avg       0.79      0.84      0.80       732\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models_knn = {\n",
    "    \"KNN_3\": KNeighborsClassifier(n_neighbors=3), # number of neighbors = 3\n",
    "    \"KNN_7\": KNeighborsClassifier(n_neighbors=7), # number of neighbors = 7\n",
    "    \"KNN_Weight_Distance\": KNeighborsClassifier(n_neighbors=5, weights='distance'), # weight by distance\n",
    "    \"KNN_Algorithm_BallTree\": KNeighborsClassifier(algorithm='ball_tree') ## algorithm choice\n",
    "}\n",
    "\n",
    "for name, model in models_knn.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    print(f\"--- {name} ---\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, predictions):.2f}\")\n",
    "    print(classification_report(y_test, predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a21842",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db049d0",
   "metadata": {},
   "source": [
    "On the preliminary metrics obtained, logistic regression and SVM are the models which obtain the most acceptable results, with recall higher than 0,6. The tweaks on the hypermparameters have achieved some improvement although it's not remarkable.  On the other hand, KNN and Random forest aren't making good predictions.\n",
    "In the end, the choice will depend on the needs of the predictions and the cost of false positives and negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1f76a1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd704e0",
   "metadata": {},
   "source": [
    "In this section 4 different architechtures have been used to develop different models in order to predict the coronary disease. \n",
    "\n",
    "To obtain the metrics for each model, the dataset has been split into two datasets in a 0.8/0.2 proportion, so no cross-validation has been done and the metrics might be optimistic.\n",
    "Class inbalanced has been adressed, and different models changing hyperparameters have been tested to try to obtain the best results. The trained models are saved in dictionaries for each architechture and the results for each model are displayed. These results include accuracy, recall and other important statistics.\n",
    "\n",
    "The results obtained show that none of the models used is perfect and some more advanced and complex models might be needed in order to obtain the best results. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (master)",
   "language": "python",
   "name": "master"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
